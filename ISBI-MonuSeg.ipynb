{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:56:47.111593Z","iopub.status.busy":"2023-10-21T17:56:47.111317Z","iopub.status.idle":"2023-10-21T17:57:10.211766Z","shell.execute_reply":"2023-10-21T17:57:10.210763Z","shell.execute_reply.started":"2023-10-21T17:56:47.111564Z"},"executionInfo":{"elapsed":3544,"status":"ok","timestamp":1674714140032,"user":{"displayName":"Arpita Roy","userId":"08870327934458985768"},"user_tz":-330},"id":"b041422f","trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import cv2\n","from glob import glob\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","import keras.backend as K\n","import tensorflow.keras.layers as L\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, MaxPool2D, Add, Dropout, Concatenate, Conv2DTranspose, Dense, Reshape, Flatten, Softmax, Lambda, UpSampling2D, AveragePooling2D, Activation, BatchNormalization, GlobalAveragePooling2D, SeparableConv2D\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import MeanIoU\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.metrics import BinaryAccuracy, Precision, Recall\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.applications import DenseNet121\n","!pip install tensorflow-wavelets\n","import tensorflow_wavelets.Layers.DWT as DWT"]},{"cell_type":"markdown","metadata":{"id":"835ef538"},"source":["# Load dataset"]},{"cell_type":"markdown","metadata":{},"source":["#### Custom Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:16.808468Z","iopub.status.busy":"2023-10-21T17:57:16.808101Z","iopub.status.idle":"2023-10-21T17:57:16.817311Z","shell.execute_reply":"2023-10-21T17:57:16.816212Z","shell.execute_reply.started":"2023-10-21T17:57:16.808437Z"},"trusted":true},"outputs":[],"source":["def load_image(path, size, mask=False):\n","    image = Image.open(path)\n","    image = image.resize((size, size))\n","\n","    if mask:\n","        image = image.convert('L')  # Convert to grayscale\n","    else:\n","        image = image.convert('RGB')  # Convert to RGB\n","    \n","    image = np.array(image)\n","    return image\n","\n","def load_data(root_path, size):\n","    images = []\n","    masks = []\n","\n","    image_folder = os.path.join(root_path, 'TissueImages')\n","    mask_folder = os.path.join(root_path, 'GroundTruth')\n","\n","    for image_path in sorted(glob(os.path.join(image_folder, '*tif'))):\n","        img_id = os.path.basename(image_path).split('.')[0]\n","        mask_path = os.path.join(mask_folder, f'{img_id}_bin_mask.png')\n","\n","        img = load_image(image_path, size) / 255.0\n","        mask = load_image(mask_path, size, mask=True) / 255.0\n","\n","        images.append(img)\n","        masks.append(mask)\n","\n","    return np.array(images), np.array(masks)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:10.225078Z","iopub.status.busy":"2023-10-21T17:57:10.224718Z","iopub.status.idle":"2023-10-21T17:57:13.599031Z","shell.execute_reply":"2023-10-21T17:57:13.598157Z","shell.execute_reply.started":"2023-10-21T17:57:10.225053Z"},"trusted":true},"outputs":[],"source":["size = 512   # image size: 512x512\n","root_path = '/kaggle/input/monuseg/MonuSeg/Training'\n","X_train, y_train = load_data(root_path, size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:18.908390Z","iopub.status.busy":"2023-10-21T17:57:18.907528Z","iopub.status.idle":"2023-10-21T17:57:20.541853Z","shell.execute_reply":"2023-10-21T17:57:20.540968Z","shell.execute_reply.started":"2023-10-21T17:57:18.908352Z"},"trusted":true},"outputs":[],"source":["size = 512   # image size: 512x512\n","root_path = '/kaggle/input/monuseg/MonuSeg/Test'\n","X_test, y_test = load_data(root_path, size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:20.543674Z","iopub.status.busy":"2023-10-21T17:57:20.543365Z","iopub.status.idle":"2023-10-21T17:57:20.549063Z","shell.execute_reply":"2023-10-21T17:57:20.548120Z","shell.execute_reply.started":"2023-10-21T17:57:20.543649Z"},"trusted":true},"outputs":[],"source":["print(f\"X shape: {X_train.shape}     |  y shape: {y_train.shape}\")\n","\n","# prepare data to modeling\n","# X = np.expand_dims(X, -1)\n","y_train = np.expand_dims(y_train, -1)\n","\n","print(f\"\\nX shape: {X_train.shape}  |  y shape: {y_train.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:21.208523Z","iopub.status.busy":"2023-10-21T17:57:21.208152Z","iopub.status.idle":"2023-10-21T17:57:21.214003Z","shell.execute_reply":"2023-10-21T17:57:21.212893Z","shell.execute_reply.started":"2023-10-21T17:57:21.208494Z"},"trusted":true},"outputs":[],"source":["print(f\"X shape: {X_test.shape}     |  y shape: {y_test.shape}\")\n","\n","# prepare data to modeling\n","# X = np.expand_dims(X, -1)\n","y_test = np.expand_dims(y_test, -1)\n","\n","print(f\"\\nX shape: {X_test.shape}  |  y shape: {y_test.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:21.907284Z","iopub.status.busy":"2023-10-21T17:57:21.906903Z","iopub.status.idle":"2023-10-21T17:57:21.992695Z","shell.execute_reply":"2023-10-21T17:57:21.991711Z","shell.execute_reply.started":"2023-10-21T17:57:21.907253Z"},"trusted":true},"outputs":[],"source":["X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n","y_train_zeros = np.zeros((24,64,64,512))\n","y_test_zeros = np.zeros((14,64,64,512))\n","y_val_zeros = np.zeros((6,64,64,512))\n","y_train_out = np.zeros((24,512,512,1))\n","y_test_out = np.zeros((14,512,512,1))\n","y_val_out = np.zeros((6,512,512,1))\n","\n","print('X_train shape:',X_train.shape)\n","print('y_train shape:',y_train.shape)\n","print('y_train_zeros shape:',y_train_zeros.shape)\n","print('X_val shape:',X_val.shape)\n","print('y_val shape:',y_val.shape)\n","print('y_val_zeros shape:',y_val_zeros.shape)\n","print('X_test shape:',X_test.shape)\n","print('y_test shape:',y_test.shape)\n","print('y_test_zeros shape:',y_test_zeros.shape)"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualization of training images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:22.908159Z","iopub.status.busy":"2023-10-21T17:57:22.907203Z","iopub.status.idle":"2023-10-21T17:57:23.312911Z","shell.execute_reply":"2023-10-21T17:57:23.311948Z","shell.execute_reply.started":"2023-10-21T17:57:22.908117Z"},"trusted":true},"outputs":[],"source":["image = X_train[1]\n","mask = y_train[1]\n","\n","fig, axes = plt.subplots(1, 2, figsize=(5, 2))\n","axes[0].imshow(image, cmap='gray')\n","axes[0].axis('off')\n","axes[0].set_title('Image')\n","\n","axes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\n","axes[1].axis('off')\n","axes[1].set_title('Mask')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualization of validation images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:23.428979Z","iopub.status.busy":"2023-10-21T17:57:23.428635Z","iopub.status.idle":"2023-10-21T17:57:23.753577Z","shell.execute_reply":"2023-10-21T17:57:23.752664Z","shell.execute_reply.started":"2023-10-21T17:57:23.428940Z"},"trusted":true},"outputs":[],"source":["image = X_val[4]\n","mask = y_val[4]\n","\n","fig, axes = plt.subplots(1, 2, figsize=(5, 2))\n","axes[0].imshow(image, cmap='gray')\n","axes[0].axis('off')\n","axes[0].set_title('Image')\n","\n","axes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\n","axes[1].axis('off')\n","axes[1].set_title('Mask')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Visualization of testing images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:23.931108Z","iopub.status.busy":"2023-10-21T17:57:23.930737Z","iopub.status.idle":"2023-10-21T17:57:24.169662Z","shell.execute_reply":"2023-10-21T17:57:24.168752Z","shell.execute_reply.started":"2023-10-21T17:57:23.931065Z"},"trusted":true},"outputs":[],"source":["image = X_test[1]\n","mask = y_test[1]\n","\n","fig, axes = plt.subplots(1, 2, figsize=(5, 2))\n","axes[0].imshow(image, cmap='gray')\n","axes[0].axis('off')\n","axes[0].set_title('Image')\n","\n","axes[1].imshow(mask*255, cmap='gray', vmin=0, vmax=1)\n","axes[1].axis('off')\n","axes[1].set_title('Mask')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Custom metrics and losses"]},{"cell_type":"markdown","metadata":{},"source":["#### Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:24.708373Z","iopub.status.busy":"2023-10-21T17:57:24.707441Z","iopub.status.idle":"2023-10-21T17:57:24.719958Z","shell.execute_reply":"2023-10-21T17:57:24.718991Z","shell.execute_reply.started":"2023-10-21T17:57:24.708324Z"},"trusted":true},"outputs":[],"source":["def dice_score(y_true, y_pred):\n","    smooth = K.epsilon()\n","    y_true_flat = K.flatten(K.cast(y_true, 'float32'))\n","    y_pred_flat = K.flatten(y_pred)\n","    intersection = K.sum(y_true_flat * y_pred_flat)\n","    score = (2. * intersection + smooth) / (K.sum(y_true_flat) + K.sum(y_pred_flat) + smooth)\n","    return score\n","\n","def iou(y_true, y_pred):\n","    smooth = K.epsilon()\n","    y_true_flat = K.flatten(K.cast(y_true, 'float32'))\n","    y_pred_flat = K.flatten(y_pred)\n","    intersection = K.sum(y_true_flat * y_pred_flat)\n","    union = K.sum(y_true_flat) + K.sum(y_pred_flat) - intersection + smooth\n","    iou = (intersection + smooth) / union\n","    return iou\n","\n","def recall(y_true, y_pred):\n","    smooth = K.epsilon()\n","    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n","    y_true_flat = K.flatten(K.cast(y_true, 'float32'))\n","    y_pred_flat = K.flatten(y_pred_pos)\n","    tp = K.sum(y_true_flat * y_pred_flat)\n","    fn = K.sum(y_true_flat * (1 - y_pred_flat))\n","    recall = (tp + smooth) / (tp + fn + smooth)\n","    return recall\n","\n","def precision(y_true, y_pred):\n","    smooth = K.epsilon()\n","    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n","    y_true_flat = K.flatten(K.cast(y_true, 'float32'))\n","    y_pred_flat = K.flatten(y_pred_pos)\n","    tp = K.sum(y_true_flat * y_pred_flat)\n","    fp = K.sum((1 - y_true_flat) * y_pred_flat)\n","    precision = (tp + smooth) / (tp + fp + smooth)\n","    return precision"]},{"cell_type":"markdown","metadata":{},"source":["#### Loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:25.626862Z","iopub.status.busy":"2023-10-21T17:57:25.626467Z","iopub.status.idle":"2023-10-21T17:57:25.636753Z","shell.execute_reply":"2023-10-21T17:57:25.635506Z","shell.execute_reply.started":"2023-10-21T17:57:25.626828Z"},"trusted":true},"outputs":[],"source":["def dice_loss(y_true, y_pred):\n","    loss = 1 - dice_score(y_true, y_pred)\n","    return loss\n","\n","def iou_loss(y_true, y_pred):\n","    loss = 1 - iou(y_true, y_pred)\n","    return loss\n","    \n","def focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n","    epsilon = tf.keras.backend.epsilon()\n","    y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n","    y_true = tf.cast(y_true, tf.float32)\n","    pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n","    focal_weight = alpha * tf.pow(1 - pt, gamma)\n","    loss = tf.reduce_mean(-focal_weight * tf.math.log(pt))\n","    return loss\n","\n","def bce_loss(y_true, y_pred):\n","    y_true = tf.cast(y_true, tf.float32)\n","    loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true, logits=y_pred))\n","    return loss\n","\n","def combined_loss(y_true, y_pred):\n","    loss = dice_loss(y_true, y_pred) + bce_loss(y_true, y_pred)\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"a8a99350"},"source":["# Custom UNet architecture"]},{"cell_type":"markdown","metadata":{},"source":["#### Instance Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:26.808106Z","iopub.status.busy":"2023-10-21T17:57:26.807506Z","iopub.status.idle":"2023-10-21T17:57:26.816518Z","shell.execute_reply":"2023-10-21T17:57:26.815395Z","shell.execute_reply.started":"2023-10-21T17:57:26.808072Z"},"trusted":true},"outputs":[],"source":["class InstanceNormalization(tf.keras.layers.Layer):\n","    def __init__(self, epsilon=1e-5):\n","        super(InstanceNormalization, self).__init__()\n","        self.epsilon = epsilon\n","\n","    def build(self, input_shape):\n","        # Create a scale parameter and a shift parameter for each channel\n","        self.scale = self.add_weight(\n","            name='scale',\n","            shape=(input_shape[-1],),\n","            initializer='ones',\n","            trainable=True\n","        )\n","        self.shift = self.add_weight(\n","            name='shift',\n","            shape=(input_shape[-1],),\n","            initializer='zeros',\n","            trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        # Calculate mean and variance for each channel independently\n","        mean = tf.reduce_mean(inputs, axis=[1, 2], keepdims=True)\n","        variance = tf.reduce_mean(tf.square(inputs - mean), axis=[1, 2], keepdims=True)\n","        \n","        # Normalize the input\n","        normalized = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n","        \n","        # Apply scale and shift\n","        output = self.scale * normalized + self.shift\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["#### Weighted GAP"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:27.308584Z","iopub.status.busy":"2023-10-21T17:57:27.307742Z","iopub.status.idle":"2023-10-21T17:57:27.315509Z","shell.execute_reply":"2023-10-21T17:57:27.314374Z","shell.execute_reply.started":"2023-10-21T17:57:27.308548Z"},"trusted":true},"outputs":[],"source":["class WeightedGlobalAveragePooling2D(tf.keras.layers.Layer):\n","    def __init__(self, num_channels, **kwargs):\n","        super(WeightedGlobalAveragePooling2D, self).__init__(**kwargs)\n","        self.num_channels = num_channels\n","        # Create a trainable weight variable for each channel\n","        self.channel_weights = self.add_weight(name='channel_weights',\n","                                              shape=(num_channels,),\n","                                              initializer='ones',\n","                                              trainable=True)\n","\n","    def call(self, inputs):\n","        # Calculate weighted global average pooling\n","        weighted_sum = tf.reduce_sum(inputs * self.channel_weights, axis=[1, 2])\n","        weighted_average = weighted_sum / tf.reduce_sum(self.channel_weights)\n","        return weighted_average\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.num_channels)"]},{"cell_type":"markdown","metadata":{},"source":["#### Gradients"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:27.808410Z","iopub.status.busy":"2023-10-21T17:57:27.807782Z","iopub.status.idle":"2023-10-21T17:57:27.813771Z","shell.execute_reply":"2023-10-21T17:57:27.812795Z","shell.execute_reply.started":"2023-10-21T17:57:27.808379Z"},"trusted":true},"outputs":[],"source":["class Gradients(L.Layer):\n","    def call(self, inputs):\n","        alpha = inputs\n","        gradients_alpha = tf.gradients(alpha, [alpha])[0]\n","        gradients_alpha = tf.reduce_mean(gradients_alpha, axis=[-1,-2, -3], keepdims=True)\n","        return gradients_alpha"]},{"cell_type":"markdown","metadata":{},"source":["#### WGCAM"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:28.507925Z","iopub.status.busy":"2023-10-21T17:57:28.507563Z","iopub.status.idle":"2023-10-21T17:57:28.517171Z","shell.execute_reply":"2023-10-21T17:57:28.516108Z","shell.execute_reply.started":"2023-10-21T17:57:28.507896Z"},"trusted":true},"outputs":[],"source":["def WGCAM(x):\n","    num_filters = x.shape[-1]\n","    wav = DWT.DWT(concat=0)(x)\n","    wav = Conv2DTranspose(num_filters*4, (2, 2), strides=2, padding=\"same\")(wav)\n","    wav = SeparableConv2D(num_filters, (1,1), padding=\"same\")(wav)\n","    x_sam = SeparableConv2D(num_filters, (1,1), padding=\"same\")(x) \n","    x_sam = wav+x_sam\n","    x_sam = SeparableConv2D(num_filters, (1,1), padding=\"same\", activation='sigmoid')(x_sam)\n","    x_cam = WeightedGlobalAveragePooling2D(num_filters)(x)\n","    x_cam = Dense(num_filters/4, activation='relu')(x_cam)\n","    x_cam = Dense(num_filters, activation='sigmoid')(x_cam)\n","    x_cam = tf.keras.layers.Reshape((1, 1, x_cam.shape[-1]))(x_cam)\n","    x = x*x_sam\n","    x = tf.keras.layers.Multiply()([x, x_cam])\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["#### Modified pooling"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:29.409128Z","iopub.status.busy":"2023-10-21T17:57:29.408398Z","iopub.status.idle":"2023-10-21T17:57:29.415614Z","shell.execute_reply":"2023-10-21T17:57:29.414626Z","shell.execute_reply.started":"2023-10-21T17:57:29.409097Z"},"trusted":true},"outputs":[],"source":["def CombinedUpsampleLayer(inputs):\n","    _,H,W,C = inputs.shape\n","    gaussian = UpSampling2D(size=(2, 2), interpolation=\"gaussian\")(inputs)\n","    lanczos = UpSampling2D(size=(2, 2), interpolation=\"lanczos5\")(inputs)\n","    combined = tf.keras.layers.Add()([gaussian, lanczos])\n","    combined_attn = Conv2D(C, 1, padding=\"same\")(combined)\n","\n","    # Assuming you want to upsample to the original input size\n","    upsampled = Conv2DTranspose(C, (2, 2), strides=2, padding=\"same\")(inputs)\n","\n","    x = Concatenate()([combined_attn,upsampled])\n","    return x"]},{"cell_type":"markdown","metadata":{},"source":["#### Teacher"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:30.016082Z","iopub.status.busy":"2023-10-21T17:57:30.015662Z","iopub.status.idle":"2023-10-21T17:57:41.334273Z","shell.execute_reply":"2023-10-21T17:57:41.333300Z","shell.execute_reply.started":"2023-10-21T17:57:30.016040Z"},"trusted":true},"outputs":[],"source":["def conv_block(inputs, num_filters):\n","    x1 = Conv2D(num_filters//2, 5, padding=\"same\")(inputs)\n","    x1 = InstanceNormalization()(x1)\n","    x1 = Activation(\"relu\")(x1)\n","    \n","    x2 = Conv2D(num_filters//2, 3, padding=\"same\")(inputs)\n","    x2 = InstanceNormalization()(x2)\n","    x2 = Activation(\"relu\")(x2)\n","    \n","    x2 = Concatenate()([x1,x2])\n","    x2 = Conv2D(num_filters, 1, padding=\"same\")(x2)\n","    \n","    x3 = Conv2D(num_filters, 1, padding=\"same\")(inputs)\n","    x3 = InstanceNormalization()(x3)\n","    x3 = Activation(\"relu\")(x3)\n","    \n","    x3 = Concatenate()([x2,x3])\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x3)\n","    x = InstanceNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def decoder_block(inputs, skip_features, num_filters):\n","    x = CombinedUpsampleLayer(inputs)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def build_densenet121_unet(input_shape):\n","    \"\"\" Input \"\"\"\n","    inputs = Input(input_shape)\n","\n","    \"\"\" Pre-trained DenseNet121 Model \"\"\"\n","    densenet = DenseNet121(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1 = densenet.get_layer(\"input_1\").output       ## 512\n","    s2 = densenet.get_layer(\"conv1/relu\").output    ## 256\n","    s3 = densenet.get_layer(\"pool2_relu\").output    ## 128\n","    s4 = densenet.get_layer(\"pool3_relu\").output    ## 64\n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = densenet.get_layer(\"pool4_relu\").output  ## 32\n","    b1 = WGCAM(b1)\n","    \n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, WGCAM(s4), 512)             ## 64\n","    d2 = decoder_block(d1, WGCAM(s3), 256)             ## 128\n","    d3 = decoder_block(d2, WGCAM(s2), 128)             ## 256\n","    d4 = decoder_block(d3, WGCAM(s1), 64)              ## 512\n","\n","    \"\"\" Outputs \"\"\"\n","    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n","\n","    model = Model(inputs, outputs, name='TEACHER')\n","    return model\n","    \n","teacher_model = build_densenet121_unet((512, 512, 3))\n","optimizer = Adam(lr=0.0001)\n","teacher_model.compile(loss=combined_loss, metrics=[\"accuracy\", dice_score, recall, precision, iou], optimizer=optimizer)\n","teacher_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T17:57:41.336246Z","iopub.status.busy":"2023-10-21T17:57:41.335906Z","iopub.status.idle":"2023-10-21T20:29:40.002120Z","shell.execute_reply":"2023-10-21T20:29:40.001277Z","shell.execute_reply.started":"2023-10-21T17:57:41.336219Z"},"trusted":true},"outputs":[],"source":["model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n","    filepath='/kaggle/working/teacher.tf',\n","    monitor='val_dice_score',\n","    save_best_only=True,\n","    save_weight_only=True,\n","    mode='max',\n","    verbose=1\n","    )\n","\n","history = teacher_model.fit(X_train, y_train,\n","                    epochs = 100,\n","                    batch_size = 2,\n","                    validation_data = (X_val,y_val),\n","                    verbose = 1,\n","                    callbacks=[model_checkpoint_callback],\n","                    shuffle = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:29:40.003793Z","iopub.status.busy":"2023-10-21T20:29:40.003491Z","iopub.status.idle":"2023-10-21T20:29:41.519802Z","shell.execute_reply":"2023-10-21T20:29:41.518699Z","shell.execute_reply.started":"2023-10-21T20:29:40.003765Z"},"trusted":true},"outputs":[],"source":["def Train_Val_Plot(loss, val_loss, dice_score, val_dice_score, iou, val_iou, recall, val_recall, precision, val_precision, accuracy, val_accuracy):\n","    fig, axs = plt.subplots(2, 3, figsize=(20, 10))\n","    fig.suptitle(\"MODEL'S METRICS VISUALIZATION\")\n","\n","    # Loss plot\n","    axs[0, 0].plot(range(1, len(loss) + 1), loss)\n","    axs[0, 0].plot(range(1, len(val_loss) + 1), val_loss)\n","    axs[0, 0].set_title('History of Loss')\n","    axs[0, 0].set_xlabel('Epochs')\n","    axs[0, 0].set_ylabel('Loss')\n","    axs[0, 0].legend(['training', 'validation'])\n","\n","    # Dice Coefficient plot\n","    axs[0, 1].plot(range(1, len(dice_score) + 1), dice_score)\n","    axs[0, 1].plot(range(1, len(val_dice_score) + 1), val_dice_score)\n","    axs[0, 1].set_title('History of Dice Coefficient')\n","    axs[0, 1].set_xlabel('Epochs')\n","    axs[0, 1].set_ylabel('Dice Coefficient')\n","    axs[0, 1].legend(['training', 'validation'])\n","\n","    # Mean IOU plot\n","    axs[0, 2].plot(range(1, len(iou) + 1), iou)\n","    axs[0, 2].plot(range(1, len(val_iou) + 1), val_iou)\n","    axs[0, 2].set_title('History of IOU')\n","    axs[0, 2].set_xlabel('Epochs')\n","    axs[0, 2].set_ylabel('IOU')\n","    axs[0, 2].legend(['training', 'validation'])\n","\n","    # Recall plot\n","    axs[1, 0].plot(range(1, len(recall) + 1), recall)\n","    axs[1, 0].plot(range(1, len(val_recall) + 1), val_recall)\n","    axs[1, 0].set_title('History of Recall')\n","    axs[1, 0].set_xlabel('Epochs')\n","    axs[1, 0].set_ylabel('Recall')\n","    axs[1, 0].legend(['training', 'validation'])\n","\n","    # Precision plot\n","    axs[1, 1].plot(range(1, len(precision) + 1), precision)\n","    axs[1, 1].plot(range(1, len(val_precision) + 1), val_precision)\n","    axs[1, 1].set_title('History of Precision')\n","    axs[1, 1].set_xlabel('Epochs')\n","    axs[1, 1].set_ylabel('Precision')\n","    axs[1, 1].legend(['training', 'validation'])\n","\n","    # Accuracy plot\n","    axs[1, 2].plot(range(1, len(accuracy) + 1), accuracy)\n","    axs[1, 2].plot(range(1, len(val_accuracy) + 1), val_accuracy)\n","    axs[1, 2].set_title('History of Accuracy')\n","    axs[1, 2].set_xlabel('Epochs')\n","    axs[1, 2].set_ylabel('Accuracy')\n","    axs[1, 2].legend(['training', 'validation'])\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","Train_Val_Plot(\n","    history.history['loss'], history.history['val_loss'],\n","    history.history['dice_score'], history.history['val_dice_score'],\n","    history.history['iou'], history.history['val_iou'],\n","    history.history['recall'], history.history['val_recall'],\n","    history.history['precision'], history.history['val_precision'],\n","    history.history['accuracy'], history.history['val_accuracy']\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:29:41.522578Z","iopub.status.busy":"2023-10-21T20:29:41.522240Z","iopub.status.idle":"2023-10-21T20:30:46.559796Z","shell.execute_reply":"2023-10-21T20:30:46.558760Z","shell.execute_reply.started":"2023-10-21T20:29:41.522542Z"},"trusted":true},"outputs":[],"source":["teacher_model.load_weights(\"/kaggle/working/teacher.tf\")\n","teacher_model.evaluate(X_test, y_test, batch_size = 4, verbose = 1)"]},{"cell_type":"markdown","metadata":{},"source":["#### Segmentation output Teacher"]},{"cell_type":"markdown","metadata":{},"source":["##### Spatial"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:30:46.561728Z","iopub.status.busy":"2023-10-21T20:30:46.561431Z","iopub.status.idle":"2023-10-21T20:30:46.600774Z","shell.execute_reply":"2023-10-21T20:30:46.599951Z","shell.execute_reply.started":"2023-10-21T20:30:46.561702Z"},"trusted":true},"outputs":[],"source":["modeller = Model(inputs=teacher_model.input, outputs=[teacher_model.get_layer(name=\"pool3_relu\").output,teacher_model.get_layer(name=\"multiply\").output,teacher_model.layers[-2].output])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:30:46.601977Z","iopub.status.busy":"2023-10-21T20:30:46.601712Z","iopub.status.idle":"2023-10-21T20:31:07.458547Z","shell.execute_reply":"2023-10-21T20:31:07.457594Z","shell.execute_reply.started":"2023-10-21T20:30:46.601953Z"},"trusted":true},"outputs":[],"source":["# Load one image and corresponding mask from the test dataset\n","test_image = X_test[0]  # Replace X_test with your actual test dataset\n","test_mask = y_test[0]  # Replace y_test with your actual test masks\n","\n","# Reshape the image to match the input shape of the model\n","test_image = np.reshape(test_image, (1,) + test_image.shape)\n","\n","# Predict the segmentation mask for the test image\n","predicted_mask = teacher_model.predict(test_image)[0]\n","feature_map1, feature_map2, feature_map3 = modeller.predict(test_image)\n","\n","# Convert the predicted mask values to binary (0 or 1)\n","predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n","\n","# Create subplots\n","fig, axes = plt.subplots(1, len(feature_map1) + 5, figsize=(20, 4))\n","\n","# Plot the test image\n","axes[0].imshow(test_image[0], cmap='gray')\n","axes[0].set_title('Test Image')\n","axes[0].axis('off')\n","\n","# Plot the ground truth mask\n","axes[1].imshow(test_mask, cmap='gray')\n","axes[1].set_title('Ground Truth Mask')\n","axes[1].axis('off')\n","\n","# Plot the predicted mask\n","axes[2].imshow(predicted_mask_binary, cmap='gray')\n","axes[2].set_title('Predicted Mask')\n","axes[2].axis('off')\n","\n","# Plot the feature maps (Set 1)\n","for i, fmap in enumerate(feature_map1):\n","    axes[i + 3].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n","    axes[i + 3].axis('off')\n","\n","# Plot the feature maps (Set 2)\n","for i, fmap in enumerate(feature_map2):\n","    axes[i + 3 + len(feature_map1)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1)].set_title(f'Feature Map {i + 1} (Set 2)')\n","    axes[i + 3 + len(feature_map1)].axis('off')\n","\n","# Plot the feature maps (Set 3)\n","for i, fmap in enumerate(feature_map3):\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].set_title(f'Feature Map {i + 1} (Set 3)')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:31:07.460305Z","iopub.status.busy":"2023-10-21T20:31:07.459971Z","iopub.status.idle":"2023-10-21T20:31:11.214828Z","shell.execute_reply":"2023-10-21T20:31:11.213915Z","shell.execute_reply.started":"2023-10-21T20:31:07.460275Z"},"trusted":true},"outputs":[],"source":["# Load one image and corresponding mask from the test dataset\n","test_image = X_test[1]  # Replace X_test with your actual test dataset\n","test_mask = y_test[1]  # Replace y_test with your actual test masks\n","\n","# Reshape the image to match the input shape of the model\n","test_image = np.reshape(test_image, (1,) + test_image.shape)\n","\n","# Predict the segmentation mask for the test image\n","predicted_mask = teacher_model.predict(test_image)[0]\n","feature_map1, feature_map2, feature_map3 = modeller.predict(test_image)\n","\n","# Convert the predicted mask values to binary (0 or 1)\n","predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n","\n","# Create subplots\n","fig, axes = plt.subplots(1, len(feature_map1) + 5, figsize=(20, 4))\n","\n","# Plot the test image\n","axes[0].imshow(test_image[0], cmap='gray')\n","axes[0].set_title('Test Image')\n","axes[0].axis('off')\n","\n","# Plot the ground truth mask\n","axes[1].imshow(test_mask, cmap='gray')\n","axes[1].set_title('Ground Truth Mask')\n","axes[1].axis('off')\n","\n","# Plot the predicted mask\n","axes[2].imshow(predicted_mask_binary, cmap='gray')\n","axes[2].set_title('Predicted Mask')\n","axes[2].axis('off')\n","\n","# Plot the feature maps (Set 1)\n","for i, fmap in enumerate(feature_map1):\n","    axes[i + 3].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n","    axes[i + 3].axis('off')\n","\n","# Plot the feature maps (Set 2)\n","for i, fmap in enumerate(feature_map2):\n","    axes[i + 3 + len(feature_map1)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1)].set_title(f'Feature Map {i + 1} (Set 2)')\n","    axes[i + 3 + len(feature_map1)].axis('off')\n","\n","# Plot the feature maps (Set 3)\n","for i, fmap in enumerate(feature_map3):\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].set_title(f'Feature Map {i + 1} (Set 3)')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:31:11.216822Z","iopub.status.busy":"2023-10-21T20:31:11.216259Z","iopub.status.idle":"2023-10-21T20:31:16.596553Z","shell.execute_reply":"2023-10-21T20:31:16.595683Z","shell.execute_reply.started":"2023-10-21T20:31:11.216790Z"},"trusted":true},"outputs":[],"source":["# Load one image and corresponding mask from the test dataset\n","test_image = X_test[2]  # Replace X_test with your actual test dataset\n","test_mask = y_test[2]  # Replace y_test with your actual test masks\n","\n","# Reshape the image to match the input shape of the model\n","test_image = np.reshape(test_image, (1,) + test_image.shape)\n","\n","# Predict the segmentation mask for the test image\n","predicted_mask = teacher_model.predict(test_image)[0]\n","feature_map1, feature_map2, feature_map3 = modeller.predict(test_image)\n","\n","# Convert the predicted mask values to binary (0 or 1)\n","predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n","\n","# Create subplots\n","fig, axes = plt.subplots(1, len(feature_map1) + 5, figsize=(20, 4))\n","\n","# Plot the test image\n","axes[0].imshow(test_image[0], cmap='gray')\n","axes[0].set_title('Test Image')\n","axes[0].axis('off')\n","\n","# Plot the ground truth mask\n","axes[1].imshow(test_mask, cmap='gray')\n","axes[1].set_title('Ground Truth Mask')\n","axes[1].axis('off')\n","\n","# Plot the predicted mask\n","axes[2].imshow(predicted_mask_binary, cmap='gray')\n","axes[2].set_title('Predicted Mask')\n","axes[2].axis('off')\n","\n","# Plot the feature maps (Set 1)\n","for i, fmap in enumerate(feature_map1):\n","    axes[i + 3].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n","    axes[i + 3].axis('off')\n","\n","# Plot the feature maps (Set 2)\n","for i, fmap in enumerate(feature_map2):\n","    axes[i + 3 + len(feature_map1)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1)].set_title(f'Feature Map {i + 1} (Set 2)')\n","    axes[i + 3 + len(feature_map1)].axis('off')\n","\n","# Plot the feature maps (Set 3)\n","for i, fmap in enumerate(feature_map3):\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].set_title(f'Feature Map {i + 1} (Set 3)')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["##### DWT"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:31:16.597999Z","iopub.status.busy":"2023-10-21T20:31:16.597697Z","iopub.status.idle":"2023-10-21T20:31:16.617359Z","shell.execute_reply":"2023-10-21T20:31:16.616463Z","shell.execute_reply.started":"2023-10-21T20:31:16.597972Z"},"trusted":true},"outputs":[],"source":["modeller = Model(inputs=teacher_model.input, outputs=[teacher_model.get_layer(name=\"dwt_1\").output,teacher_model.get_layer(name=\"dwt_2\").output,teacher_model.get_layer(name=\"dwt_3\").output])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:31:16.620717Z","iopub.status.busy":"2023-10-21T20:31:16.620439Z","iopub.status.idle":"2023-10-21T20:31:19.881126Z","shell.execute_reply":"2023-10-21T20:31:19.879967Z","shell.execute_reply.started":"2023-10-21T20:31:16.620693Z"},"trusted":true},"outputs":[],"source":["# Load one image and corresponding mask from the test dataset\n","test_image = X_test[0]  # Replace X_test with your actual test dataset\n","test_mask = y_test[0]  # Replace y_test with your actual test masks\n","\n","# Reshape the image to match the input shape of the model\n","test_image = np.reshape(test_image, (1,) + test_image.shape)\n","\n","# Predict the segmentation mask for the test image\n","predicted_mask = teacher_model.predict(test_image)[0]\n","feature_map1, feature_map2, feature_map3 = modeller.predict(test_image)\n","\n","# Convert the predicted mask values to binary (0 or 1)\n","predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n","\n","# Create subplots\n","fig, axes = plt.subplots(1, len(feature_map1) + 5, figsize=(20, 4))\n","\n","# Plot the test image\n","axes[0].imshow(test_image[0], cmap='gray')\n","axes[0].set_title('Test Image')\n","axes[0].axis('off')\n","\n","# Plot the ground truth mask\n","axes[1].imshow(test_mask, cmap='gray')\n","axes[1].set_title('Ground Truth Mask')\n","axes[1].axis('off')\n","\n","# Plot the predicted mask\n","axes[2].imshow(predicted_mask_binary, cmap='gray')\n","axes[2].set_title('Predicted Mask')\n","axes[2].axis('off')\n","\n","# Plot the feature maps (Set 1)\n","for i, fmap in enumerate(feature_map1):\n","    axes[i + 3].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n","    axes[i + 3].axis('off')\n","\n","# Plot the feature maps (Set 2)\n","for i, fmap in enumerate(feature_map2):\n","    axes[i + 3 + len(feature_map1)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1)].set_title(f'Feature Map {i + 1} (Set 2)')\n","    axes[i + 3 + len(feature_map1)].axis('off')\n","\n","# Plot the feature maps (Set 3)\n","for i, fmap in enumerate(feature_map3):\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].set_title(f'Feature Map {i + 1} (Set 3)')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-21T20:31:19.883269Z","iopub.status.busy":"2023-10-21T20:31:19.882890Z","iopub.status.idle":"2023-10-21T20:31:22.438259Z","shell.execute_reply":"2023-10-21T20:31:22.437323Z","shell.execute_reply.started":"2023-10-21T20:31:19.883236Z"},"trusted":true},"outputs":[],"source":["# Load one image and corresponding mask from the test dataset\n","test_image = X_test[1]  # Replace X_test with your actual test dataset\n","test_mask = y_test[1]  # Replace y_test with your actual test masks\n","\n","# Reshape the image to match the input shape of the model\n","test_image = np.reshape(test_image, (1,) + test_image.shape)\n","\n","# Predict the segmentation mask for the test image\n","predicted_mask = teacher_model.predict(test_image)[0]\n","feature_map1, feature_map2, feature_map3 = modeller.predict(test_image)\n","\n","# Convert the predicted mask values to binary (0 or 1)\n","predicted_mask_binary = np.where(predicted_mask > 0.5, 1, 0) * 255\n","\n","# Create subplots\n","fig, axes = plt.subplots(1, len(feature_map1) + 5, figsize=(20, 4))\n","\n","# Plot the test image\n","axes[0].imshow(test_image[0], cmap='gray')\n","axes[0].set_title('Test Image')\n","axes[0].axis('off')\n","\n","# Plot the ground truth mask\n","axes[1].imshow(test_mask, cmap='gray')\n","axes[1].set_title('Ground Truth Mask')\n","axes[1].axis('off')\n","\n","# Plot the predicted mask\n","axes[2].imshow(predicted_mask_binary, cmap='gray')\n","axes[2].set_title('Predicted Mask')\n","axes[2].axis('off')\n","\n","# Plot the feature maps (Set 1)\n","for i, fmap in enumerate(feature_map1):\n","    axes[i + 3].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3].set_title(f'Feature Map {i + 1} (Set 1)')\n","    axes[i + 3].axis('off')\n","\n","# Plot the feature maps (Set 2)\n","for i, fmap in enumerate(feature_map2):\n","    axes[i + 3 + len(feature_map1)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1)].set_title(f'Feature Map {i + 1} (Set 2)')\n","    axes[i + 3 + len(feature_map1)].axis('off')\n","\n","# Plot the feature maps (Set 3)\n","for i, fmap in enumerate(feature_map3):\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].imshow(fmap[:, :, 0], cmap='jet')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].set_title(f'Feature Map {i + 1} (Set 3)')\n","    axes[i + 3 + len(feature_map1) + len(feature_map2)].axis('off')\n","\n","plt.tight_layout()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
